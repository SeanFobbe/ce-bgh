---
title: "Compilation Report | Corpus der Entscheidungen des Bundesgerichtshofs (CE-BGH)"
author: Seán Fobbe
geometry: margin=3cm
fontsize: 11pt
papersize: a4
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    pandoc_args: --listings
    includes:
      in_header: tex/Preamble_DE.tex
      before_body: [temp/Definitions.tex, tex/Titlepage_Compilation.tex]
bibliography: temp/packages.bib
nocite: '@*'
---



```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = TRUE,
                      message = TRUE,
                      collapse = TRUE,
                      comment = "#>")
```




```{r, results = "asis", echo = FALSE}
cat(readLines("README.md"),
    sep = "\n")
```



# Packages laden


```{r}

library(targets)
library(tarchetypes)
library(RcppTOML)
library(future)
library(data.table)
library(quanteda)
library(knitr)
library(kableExtra)
library(igraph)
library(ggraph)

tar_unscript()
```



# Vorbereitung

## Definitionen

```{r}

## Datum
datestamp <- Sys.Date()
print(datestamp)

## Datum und Uhrzeit (Beginn)
begin.script <- Sys.time()

## Konfiguration
config <- RcppTOML::parseTOML("config.toml")
print(config)


# Analyse-Ordner
dir.analysis <- paste0(getwd(),
                       "/analysis")


```


## Aufräumen

Löscht Dateien im Output-Ordner, die nicht aktuell genug sind.


```{r}

unlink(grep(datestamp,
            list.files("output",
                       full.names = TRUE),
            invert = TRUE,
            value = TRUE))


## files.html <- list.files("files/html", full.names = TRUE)


## if(length(files.html) > 0){

##     delete <- sort(files.html, decreasing = TRUE)[1:10]
##     unlink(delete)

## }



```



## Ordner erstellen

```{r}

#unlink("output", recursive = TRUE)
dir.create("files", showWarnings = FALSE)
dir.create("output", showWarnings = FALSE)
dir.create("temp", showWarnings = FALSE)

dir.create(dir.analysis, showWarnings = FALSE)

```



## Vollzitate statistischer Software schreiben

```{r}
knitr::write_bib(renv::dependencies()$Package,
                 "temp/packages.bib")
```




# Globale Variablen


## Packages definieren

```{targets global-packages, tar_globals = TRUE}

tar_option_set(packages = c("tarchetypes",
                            "RcppTOML",     # TOML-Dateien lesen und schreiben
							"testthat",     # Unit Tests
                            "fs",           # Verbessertes File Handling
                            "zip",          # Verbessertes ZIP Handling
                            "mgsub",        # Vektorisiertes Gsub
                            "httr",         # HTTP-Werkzeuge
                            "rvest",        # HTML/XML-Extraktion
                            "knitr",        # Professionelles Reporting
                            "kableExtra",   # Verbesserte Kable Tabellen
                            "pdftools",     # Verarbeitung von PDF-Dateien
                            "ggplot2",      # Datenvisualisierung
							"ggraph",       # Visualisierung von Graphen
                            "scales",       # Skalierung von Diagrammen
                            "data.table",   # Fortgeschrittene Datenverarbeitung
                            "readtext",     # TXT-Dateien einlesen
                            "quanteda",     # Computerlinguistik
                            "future",       # Parallelisierung
                            "future.apply"))# Funktionen für Future

tar_option_set(workspace_on_error = TRUE) # Save Workspace on Error
tar_option_set(format = "qs")

```


## Konfiguration


```{targets global-config, tar_globals = TRUE}

datestamp <- Sys.Date()

config <- RcppTOML::parseTOML("config.toml")

dir.analysis <- paste0(getwd(),
                       "/analysis")

## Caption for diagrams
caption <- paste("Fobbe | DOI:",
                 config$doi$data$version)


## Prefix for figure titles
prefix.figuretitle <- paste(config$project$shortname,
                            "| Version",
                            datestamp)

## File prefix
prefix.files <- paste0(config$project$shortname,
                       "_",
                       datestamp)


if (config$cores$max == TRUE){
    fullCores <- future::availableCores() - 1
}


if (config$cores$max == FALSE){
    fullCores <- as.integer(config$cores$number)
}

```




## Funktionen definieren

```{targets global-functions, tar_globals = TRUE}

lapply(list.files("functions", pattern = "\\.R$", full.names = TRUE), source)

```



## Metadaten für TXT-Dateien definieren

```{targets global-txtvars, tar_globals = TRUE}

docvarnames <- c("gericht",
                 "spruchkoerper_db",
                 "leitsatz",
                 "datum",
                 "spruchkoerper_az",
                 "registerzeichen",
                 "eingangsnummer",
                 "eingangsjahr_az",
                 "zusatz_az",
                 "name",
                 "kollision")

```


## ZIP-Datei für Source definieren

```{targets global-sourcefiles, tar_globals = TRUE}

files.source.raw <-  c(list.files(pattern = "\\.R$|\\.toml$|\\.md$|\\.Rmd$"),
					   "reports",
                       "data",
                       "functions",
                       "tex",
                       "gpg",
                       "buttons",
                       list.files(pattern = "renv\\.lock|\\.Rprofile",
                                  all.files = TRUE),
                       list.files("renv",
                                  pattern = "activate\\.R",
                                  full.names = TRUE))

```






# Pipeline: Konstruktion




## File Tracking Targets

Mit diesem Abschnitt der Pipeline werden Input-Dateien getrackt und eingelesen. Mit der Option \enquote{format = "file"} werden für Input-Dateien Prüfsummen berechnet. Falls sich diese verändern werden alle von ihnen abhängigen Pipeline-Schritte als veraltet markiert und neu berechnet.




### Variablen

Die Variablen des Datensatzes, inklusive ihrer Erläuterung.


```{targets tar.file.var}
list(
    tar_target(file.variables.codebook,
               "data/CE-BGH_Variables.csv",
               format = "file"),
    tar_target(variables.codebook,
               fread(file.variables.codebook))
)
```



### Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD)

Die Tabelle der Registerzeichen und der ihnen zugeordneten Verfahrensarten stammt aus dem folgenden Datensatz: \enquote{Seán Fobbe (2021). Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD). Version 1.0.1. Zenodo. DOI: 10.5281/zenodo.4569564.}

`

```{targets tar.file.az}
list(
    tar_target(file.az.brd,
           "data/AZ-BRD_1-0-1_DE_Registerzeichen_Datensatz.csv",
           format = "file"),
     tar_target(az.brd,
                fread(file.az.brd))
     )
```

### Presidents and Vice-Presidents of the Federal Courts of Germany (PVP-FCG)

 Die Personendaten stammen aus folgendem Datensatz: \enquote{Seán Fobbe and Tilko Swalve (2021). Presidents and Vice-Presidents of the Federal Courts of Germany (PVP-FCG). Version 2021-04-08. Zenodo. DOI: 10.5281/zenodo.4568682}.


```{targets tar.file.presi}
list(
    tar_target(file.presidents,
           "data/PVP-FCG_2021-04-08_GermanFederalCourts_Presidents.csv",
           format = "file"),
     tar_target(presidents,
                fread(file.presidents))
     )
```



```{targets tar.file.vpresi}
list(
    tar_target(file.vpresidents,
           "data/PVP-FCG_2021-04-08_GermanFederalCourts_VicePresidents.csv",
           format = "file"),
     tar_target(vpresidents,
                fread(file.vpresidents))
     )
```




### Source Code

Dies sind alle Dateien, die den Source Code für den Datensatz bereitstellen.

```{targets tar.file.source}
tar_target(files.source,
           files.source.raw,
           format = "file")

```



### Changelog

```{targets tar.file.changelog}
tar_target(changelog,
           "CHANGELOG.md",
           format = "file")
```



## Download Targets


### Maximalen Umfang der Datenbankabfrage bestimmen



```{targets tar.download.scope}

tarchetypes::tar_age(dt.scope,
                     f.scope(debug.toggle = config$debug$toggle,
                             debug.pages = config$debug$pages),
                     age = as.difftime(1, units = "days"))

```
	


### Datenbankseiten als HTML abrufen



```{targets tar.download.html}
tar_target(files.html,
                f.download(url = dt.scope$url,
                           filename = dt.scope$filename,
                           dir = "files/html",
                           sleep.min = 0.2,
                           sleep.max = 0.5,
                           retries = 3,
                           retry.sleep.min = 2,
                           retry.sleep.max = 5,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```





### Vorläufige Download-Tabelle erstellen

Abfrage der Datenbank des BGH und erstellen der vorläufigen Download-Tabelle.

```{targets tar.download.make}
tar_target(dt.download,
           f.download_table_make(files.html = files.html))

```
	

### Download-Tabelle bereinigen

Die Aktenzeichen und Spruchkörper werden bereinigt und gespeichert.

```{targets tar.download.clean}

list(
    tar_target(az_clean,
                f.clean_az_bgh(dt.download$az)),
    tar_target(spruch_clean,
               f.clean_spruch_bgh(dt.download$spruch))
    )
				
				
```

### Finale Download-Tabelle erstellen

Die bereinigten Variablen werden hier mit der vorläufigen Download-Tabelle zusammengeführt, weitere Bereinigungen durchgeführt, weitere Variablen aus den Bemerkungen extrahiert und schließlich auf ihre Konformität mit der Beschreibung im Codebook getestet.



```{targets tar.download.final}

tar_target(dt.download.final,
           f.download_table_finalize(x = dt.download,
                                     az = az_clean,
                                     spruch = spruch_clean))
```



### Download durchführen


```{targets tar.download.pdf}
tar_target(files.pdf,
                f.download(url = dt.download.final$url,
                           filename = dt.download.final$doc_id,
                           dir = "files/pdf",
                           sleep.min = 0,
                           sleep.max = 0.1,
                           retries = 3,
                           retry.sleep.min = 2,
                           retry.sleep.max = 5,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```




## Convert Targets

Durch diesen Abschnitt der Pipeline werden die PDF-Dateien in TXT konvertiert und mitsamt den Variablen in ihren Dateinamen eingelesen. Beim Einlesen werden die in PDF-Dateien üblichen über Zeilen gebrochene Wörter wieder zusammengefügt.




```{targets tar.convert}

list(tar_target(files.txt,
                f.tar_pdf_extract(x = files.pdf,
                                  outputdir = "files/txt",
								  multicore = config$parallel$extractPDF,
                                  cores = fullCores),
                format = "file"),
     tar_target(dt.bgh,
                f.readtext(x = files.txt,
                           docvarnames = docvarnames))
     )
					
```					


## Enhance Targets

Dieser Abschnitt der Pipeline berechnet diverse Verbesserungen für den Datensatz und führt diese am Ende zusammen.


### Daten standardisieren

Das Datum wird im ISO-Format standardisiert und die Variablen \enquote{entscheidungsjahr} und \enquote{eingangsjahr\_iso} hinzugefügt.


```{targets tar.enhance.dates}
tar_target(dt.bgh.datecleaned,
                f.clean_dates(dt.bgh))
```


### Variable erstellen: \enquote{verfahrensart}

Die Variable \enquote{verfahrensart} wird aus den Registerzeichen berechnet.

```{targets tar.enhance.verfahrensart}
tar_target(var_verfahrensart,
                f.var_verfahrensart(dt.bgh.datecleaned$registerzeichen,
                                    az.brd = az.brd,
                                    gericht = "BGH"))
```





### Variable erstellen: \enquote{aktenzeichen}

Das Aktenzeichen wird aus seinen Komponenten berechnet.


```{targets tar.enhance.az}
tar_target(var_aktenzeichen,
                f.var_aktenzeichen(x = dt.bgh.datecleaned,
                                   az.brd = az.brd,
                                   gericht = "BGH"))
```



### Variable erstellen: \enquote{ecli}

Die ECLI wird aus ihren Komponenten berechnet.



```{targets tar.enhance.ecli}
tar_target(var_ecli,
           f.var_ecli_bgh(x = dt.bgh.datecleaned,
                          az.brd = az.brd))
```




### Variable erstellen: \enquote{praesi}


```{targets tar.enhance.praesi}
tar_target(var_praesi,
           f.presidents(datum = dt.bgh.datecleaned$datum,
                        gericht = "BGH",
						pvp.fcg = presidents))
```

### Variable erstellen: \enquote{vpraesi}


```{targets tar.enhance.vpraesi}
tar_target(var_vpraesi,
           f.presidents(datum = dt.bgh.datecleaned$datum,
                        gericht = "BGH",
						pvp.fcg = vpresidents))
```






### Variable erstellen: \enquote{entscheidung\_typ}

Der Typ der Entscheidung wird aus dem Text extrahiert.


```{targets tar.enhance.entschtyp}
tar_target(var_entscheidung_typ,
                f.var_entscheidung_typ(dt.bgh.datecleaned$text))
```


### Variablen erstellen: \enquote{bghst, bghr, nachschlagewerk}

```{targets tar.enhance.sammlungen}

tar_target(var_sammlungen,
                f.var_sammlungen(dt.bgh.datecleaned$text))

```



### Variablen erstellen: \enquote{zeichen, token, typen, saetze}

Berechnung klassischer linguistischer Kennzahlen.



```{targets tar.enhance.lingstats}
tar_target(var_lingstats,
                f.lingstats(dt.bgh.datecleaned,
                            multicore = config$parallel$lingsummarize,
                            cores = fullCores,
                            germanvars = TRUE))
```





### Konstanten erstellen

Konstanten die dem Datensatz wichtige Herkunftsinformationen hinzufügen. Darunter sind die Versionsnummer, die Version DOI, die Concept DOI und die Lizenz.



```{targets tar.enhance.constants}
tar_target(var_constants,
           data.frame(version = as.character(datestamp),
                      doi_concept = config$doi$data$concept,
                      doi_version = config$doi$data$version,
                      lizenz = as.character(config$license$data))[rep(1,
                                                                      nrow(dt.bgh.datecleaned)),])
```





### Zusätzliche Variablen zusammenführen

```{targets tar.enhance.unify}
tar_target(vars_additional,
           data.table(verfahrensart = var_verfahrensart,
                      aktenzeichen = var_aktenzeichen,
                      ecli = var_ecli,
                      praesi = var_praesi,
                      v_praesi = var_vpraesi,
					  entscheidung_typ = var_entscheidung_typ,
                      var_lingstats,
					  var_sammlungen,
                      var_constants))

```



### Finalen Datensatz erstellen

Die Verbesserungen der vorherigen Schritte werden in dieser Funktion zusammengefügt um den finalen Datenatz herzustellen.


```{targets tar.enhance.final}
tar_target(dt.bgh.final,
           f.finalize(x = dt.bgh.datecleaned,
                      download.table = dt.download.final,
                      vars.additional = vars_additional,
                      varnames = variables.codebook$varname))

```


### Variante erstellen: Nur Metadaten

Hier wird die Text-Variable entfernt, um eine deutlich platzsparendere Variante des Datensatzes zu erstellen. Enthalten sind nur noch die Metadaten.



```{targets tar.enhance.meta}
tar_target(dt.bgh.meta,
                dt.bgh.final[, !"text"])

```





## Zitations-Analyse



```{targets tar.citation}
tar_target(igraph.citations.az,
           f.citation_network(dt.bgh.final = dt.bgh.final,
                              az.brd = az.brd,
                              multicore = config$parallel$citations,
                              cores = fullCores))

```






## Write Targets

Dieser Abschnitt der Pipeline schreibt den Datensatz und alle Hash-Prüfsummen auf die Festplatte.



### CSV schreiben: Voller Datensatz

```{targets tar.write.final}
tar_target(csv.final,
           f.tar_fwrite(x = dt.bgh.final,
                        filename = file.path("output",
                                             paste0(prefix.files,
                                                    "_DE_CSV_Datensatz.csv"))
                        )
           )
```



### CSV schreiben: Metadaten


```{targets tar.write.meta}
tar_target(csv.meta,
           f.tar_fwrite(x = dt.bgh.meta,
                        filename = file.path("output",
                                             paste0(prefix.files,
                                                    "_DE_CSV_Metadaten.csv"))
                        )
           )
```


### GraphML schreiben: Aktenzeichen-Netzwerke

```{targets tar.write.graphs.az}

tar_target(graphml.citations.az, 
           f.tar_write_graph(graph = igraph.citations.az,
                             file = file.path("output",
                                              paste0(prefix.files, 
                                                     "_DE_GraphML_AZ-Zitiernetzwerk.graphml")),
                             format = "graphml"),
           format = "file")

```




## Report Targets

Dieser Abschnitt der Pipeline erstellt die finalen Berichte (Codebook und Robustness Checks).



### LaTeX-Definitionen schreiben

Um Variablen aus der Pipeline in die LaTeX-Kompilierung einzuführen, müssen diese als .tex-Datei auf die Festplatte geschrieben werden.

```{targets tar.report.latexdefs}
tar_target(latexdefs,
                f.latexdefs(config,
                            dir = "temp",
                            version = datestamp),
	       format = "file")

```

### Zusammenfassungen linguistischer Kennwerte berechnen

```{targets tar.report.lingstat.summ}
tar_target(lingstats.summary,
                f.lingstats_summary(dt.bgh.final,
                                    germanvars = TRUE))

```


### Report erstellen: Robustness Checks

```{targets tar.report.robustness}
tarchetypes::tar_render(report.robustness,
                        file.path("reports",
                                  "RobustnessChecks.Rmd"),
                        output_file = file.path("../output",
                                                paste0(config$project$shortname,
                                                       "_",
                                                       datestamp,
                                                       "_RobustnessChecks.pdf")))

```



### Report erstellen: Codebook



```{targets tar.report.codebook}
tarchetypes::tar_render(report.codebook,
                        file.path("reports",
                                  "Codebook.Rmd"),
                        output_file = file.path("../output",
                                                paste0(config$project$shortname,
                                                       "_",
                                                       datestamp,
                                                       "_Codebook.pdf")))

```




## ZIP Targets

Diese Abschnitt der Pipeline erstellt ZIP-Archive für alle zentralen Rechenergebnisse und speichert diese im Ordner \enquote{output}.





### ZIP erstellen: Analyse-Dateien

```{targets tar.zip.analysis}
tar_target(zip.analysis,
           f.tar_zip("analysis/",
                     filename = paste(prefix.files,
                                      "DE_Analyse.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick",
                     report.codebook,    # manually enforced dependency relationship
                     report.robustness), # manually enforced dependency relationship
           format = "file")
```





### ZIP erstellen: Source Code


```{targets tar.zip.source}
tar_target(zip.source,
                f.tar_zip(files.source,
                              filename = paste0(prefix.files,
                                                "_Source_Code.zip"),
                              dir = "output",
                              mode = "mirror"),
                format = "file")
```






### ZIP erstellen: PDF-Dateien (alle Entscheidungen)

Hinweis: die verpackten PDF-Dateien werden auf die im finalen Datensatz enthaltenen Dokumente beschränkt (Bereinigung um Platzhalter-Dokumente).


```{targets tar.zip.pdf.all}

tar_target(zip.pdf.all,
           f.tar_zip(x = intersect(files.pdf,
                                   file.path("files", "pdf",
                                             gsub("\\.txt",
                                                  "\\.pdf",
                                                  dt.bgh.final$doc_id))),
                     filename = paste(prefix.files,
                                      "DE_PDF_Datensatz.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick"),
           format = "file")


```



### ZIP erstellen: PDF-Dateien (nur Leitsatzentscheidungen)

```{targets tar.zip.pdf.leit}

tar_target(zip.pdf.leitsatz,
           f.tar_zip(x = intersect(files.pdf,
                                   file.path("files", "pdf",
                                             gsub("\\.txt",
                                                  "\\.pdf",
                                                  dt.bgh.final[leitsatz == "LE"]$doc_id))),
                     filename = paste(prefix.files,
                                      "DE_PDF_Leitsatz-Entscheidungen.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick"),
           format = "file")
```




### ZIP erstellen: PDF-Dateien (nur benannte Entscheidungen)

```{targets tar.zip.pdf.named}
tar_target(zip.pdf.benannt,
                f.tar_zip(x = intersect(files.pdf,
                                   file.path("files", "pdf",
                                             gsub("\\.txt",
                                                  "\\.pdf",
                                                  dt.bgh.final[is.na(name) == FALSE]$doc_id))),
                              filename = paste(prefix.files,
                                               "DE_PDF_Entscheidungen-mit-Namen.zip",
                                               sep = "_"),
                              dir = "output",
                              mode = "cherry-pick"),
                format = "file")
```




### ZIP erstellen: PDF-Dateien (Platzhalter)

```{targets tar.zip.pdf.placeholder}
tar_target(zip.pdf.platzhalter,
           f.tar_zip(x = setdiff(files.pdf,
                                 file.path("files", "pdf",
                                           gsub("\\.txt",
                                                "\\.pdf",
                                                dt.bgh.final$doc_id))),
                     filename = paste(prefix.files,
                                      "DE_PDF_Platzhalter.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick"),
           format = "file")
```





### ZIP erstellen: TXT-Dateien

```{targets tar.zip.txt}
tar_target(zip.txt,
           f.tar_zip(x = intersect(files.txt, file.path("files", "txt", dt.bgh.final$doc_id)),
                     filename = paste(prefix.files,
                                      "DE_TXT_Datensatz.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick"),
           format = "file")
```


### ZIP erstellen: CSV-Datei (voller Datensatz)


```{targets tar.zip.csv.full}
tar_target(zip.csv.final,
                f.tar_zip(csv.final,
                              filename = gsub("\\.csv", "\\.zip", basename(csv.final)),
                              dir = "output",
                              mode = "cherry-pick"),
                format = "file")
```



### ZIP erstellen: CSV-Datei (nur Metadaten)


```{targets tar.zip.csv.meta}
tar_target(zip.csv.meta,
                f.tar_zip(csv.meta,
                              filename = gsub("\\.csv", "\\.zip", basename(csv.meta)),
                              dir = "output",
                              mode = "cherry-pick"),
                format = "file")
```



### ZIP erstellen: GraphML


```{targets tar.zip.graphml}
tar_target(zip.citations.az,
                f.tar_zip(graphml.citations.az,
                              filename = paste0(prefix.files,
                                                "_DE_GraphML_AZ-Zitiernetzwerk.zip"),
                              dir = "output",
                              mode = "cherry-pick"),
                format = "file")
```










## Kryptographische Hashes

### Zu hashende ZIP-Archive definieren


```{targets tar.hashes.all}
tar_target(zip.all,
           c(zip.pdf.all,
             zip.pdf.leitsatz,
             zip.pdf.benannt,
			 zip.pdf.platzhalter,
             zip.txt,
			 zip.citations.az,
             zip.csv.final,
             zip.csv.meta,
             zip.analysis,
             zip.source))
```

### Kryptographische Hashes berechnen


```{targets tar.hashes.calc}
tar_target(hashes,
           f.tar_multihashes(c(zip.all,
                               report.codebook[1],
                               report.robustness[1]),
                             multicore = config$parallel$multihashes,
                             cores = fullCores))
```



### CSV schreiben: Kryptographische Hashes


```{targets tar.hashes.csv}
tar_target(csv.hashes,
           f.tar_fwrite(x = hashes,
                        filename = file.path("output",
                                             paste0(prefix.files,
                                                    "_KryptographischeHashes.csv"))
                        )
           )
```









# Pipeline: Kompilierung



## Durchführen der Kompilierung

```{r pipeline-run, results = "hide"}
tar_make()
```



## Visualisierung

```{r, pipeline-graph, fig.width = 12, fig.height = 18}

edgelist <- tar_network(targets_only = TRUE)$edges
setDT(edgelist)

g  <- igraph::graph.data.frame(edgelist,
                               directed = TRUE)


ggraph(g,
       'sugiyama') + 
    geom_edge_diagonal(colour = "grey")+
    geom_node_point()+
    geom_node_text(aes(label = name),
                   size = 2,
                   repel = TRUE)+
    theme_void()

```
                       



# Pipeline: Analyse


## Gesamte Liste

Die vollständige Liste aller Targets, inklusive ihres Types und ihrer Größe. Targets die auf Dateien verweisen (z.B. alle PDF-Dateien) geben die Gesamtgröße der Dateien auf der Festplatte an.




```{r, pipeline-list}

meta <- tar_meta(fields = c("type", "bytes", "format"), complete_only = TRUE)
setDT(meta)
meta$MB <- round(meta$bytes / 1e6, digits = 2)

# Gesamter Speicherplatzverbrauch
sum(meta$MB, na.rm = TRUE)

kable(meta[order(type, name)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```



\newpage
## Timing

### Gesamte Laufzeit

```{r, pipeline-runtime}
meta <- tar_meta(fields = c("time", "seconds"), complete_only = TRUE)
setDT(meta)
meta$mins <- round(meta$seconds / 60, digits = 2)

runtime.sum <- sum(meta$seconds)

## Sekunden
print(runtime.sum)

## Minuten
runtime.sum / 60

## Stunden
runtime.sum / 3600
```

### Laufzeit einzelner Targets

Der Zeitpunkt an dem die Targets berechnet wurden und ihre jeweilige Laufzeit in Sekunden.


```{r, pipeline-timing}
kable(meta[order(-seconds)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```



\newpage
## Warnungen



```{r, pipline-warnings, results = 'asis'}

meta <- tar_meta(fields = "warnings", complete_only = TRUE)
setDT(meta)
meta$warnings <- gsub("(\\.pdf|\\.html?|\\.txt)", "\\1 \n\n", meta$warnings)

if (meta[,.N > 0]){

    for(i in 1:meta[,.N]){

        cat(paste("###", meta[i]$name), "\n\n")
        cat(paste(meta[i]$warnings, "\n\n"))
        
    }

}else{

    cat("No warnings to report.")

}

```



\newpage
## Fehlermeldungen

```{r, pipeline-errors}

meta <- tar_meta(fields = "error", complete_only = TRUE)
setDT(meta)

if (meta[,.N > 0]){

    for(i in 1:meta[,.N]){

        cat(paste("###", meta[i]$name), "\n\n")
        cat(paste(meta[i]$error, "\n\n"))
        
    }

}else{

    cat("No errors to report.")

}


```



# Dateigrößen




## ZIP und CSV-Dateien



## ZIP-Dateien

```{r filesize.zip}

files <- list.files("output", pattern = "\\.zip", full.names = TRUE)

filesize <- round(file.size(files) / 10^6, digits = 2)

table.size <- data.table(basename(files),
                         filesize)


kable(table.size,
      format = "latex",
      align = c("l", "r"),
      format.args = list(big.mark = ","),
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Datei",
                    "Größe in MB"))

```

\newpage
## CSV-Dateien

```{r filesize.csv}

files <- list.files("output", pattern = "\\.csv", full.names = TRUE)

filesize <- round(file.size(files) / 10^6, digits = 2)

table.size <- data.table(basename(files),
                         filesize)


kable(table.size,
      format = "latex",
      align = c("l", "r"),
      format.args = list(big.mark = ","),
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Datei",
                    "Größe in MB"))

```




## PDF-Dateien (MB)

```{r}
tar_load(files.pdf)
pdf.MB <- file.size(files.pdf) / 10^6
sum(pdf.MB)
```


## TXT-Dateien (MB)


```{r}
tar_load(files.txt)
txt.MB <- file.size(files.txt) / 10^6
sum(txt.MB)
```







# Kryptographische Signaturen

## Signaturen laden

```{r}
tar_load(hashes)
```


## Leerzeichen hinzufügen um bei SHA3-512 Zeilenumbruch zu ermöglichen

Hierbei handelt es sich lediglich um eine optische Notwendigkeit. Die normale 128 Zeichen lange Zeichenfolge von SHA3-512-Signaturen wird ansonsten nicht umgebrochen und verschwindet über die Seitengrenze. Das Leerzeichen erlaubt den automatischen Zeilenumbruch und damit einen für Menschen sinnvoll lesbaren Abdruck im Codebook. Diese Variante wird nur zur Anzeige verwendet und danach verworfen.

```{r}
hashes$sha3.512 <- paste(substr(hashes$sha3.512, 1, 64),
                              substr(hashes$sha3.512, 65, 128))
```



## In Bericht anzeigen

```{r}

kable(hashes[,.(index,filename)],
      format = "latex",
      align = c("p{1cm}",
                "p{13cm}"),
      booktabs = TRUE,
      longtable = TRUE)

kable(hashes[,.(index,sha2.256)],
      format = "latex",
      align = c("c",
                "p{13cm}"),
      booktabs = TRUE,
      longtable = TRUE)


```

\newpage

```{r}
kable(hashes[,.(index,sha3.512)],
      format = "latex",
      align = c("c",
                "p{13cm}"),
      booktabs = TRUE,
      longtable = TRUE)
```







\newpage

```{r, results = "asis", echo = FALSE}
cat(readLines("CHANGELOG.md"),
    sep = "\n")

```


# Abschluss

```{r}

## Datumsstempel
print(datestamp) 

## Datum und Uhrzeit (Anfang)
print(begin.script)


## Datum und Uhrzeit (Ende)
end.script <- Sys.time()
print(end.script)


## Laufzeit des gesamten Skriptes
print(end.script - begin.script)

```


# Parameter für strenge Replikationen


```{r}
system2("openssl", "version", stdout = TRUE)

sessionInfo()

```


# Literaturverzeichnis
