---
title: "Compilation Report | Corpus der Entscheidungen des Bundesgerichtshofs (CE-BGH)"
author: Seán Fobbe
geometry: margin=3cm
fontsize: 11pt
papersize: a4
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    pandoc_args: --listings
    includes:
      in_header: tex/Preamble_DE.tex
      before_body: [temp/Definitions.tex, tex/Titlepage_Compilation.tex]
bibliography: temp/packages.bib
nocite: '@*'
---



```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = TRUE,
                      message = TRUE,
                      collapse = TRUE,
                      comment = "#>")
```




```{r, results = "asis", echo = FALSE}
cat(readLines("README.md"),
    sep = "\n")
```



# Packages laden


```{r}

library(targets)
library(tarchetypes)
library(RcppTOML)
library(future)
library(data.table)
library(quanteda)
library(knitr)
library(kableExtra)
library(igraph)
library(ggraph)

tar_unscript()
```



# Vorbereitung

## Definitionen

```{r}

## Datum
datestamp <- Sys.Date()
print(datestamp)

## Datum und Uhrzeit (Beginn)
begin.script <- Sys.time()

## Konfiguration
config <- RcppTOML::parseTOML("config.toml")
print(config)


# Analyse-Ordner
dir.analysis <- paste0(getwd(),
                       "/analysis")


```


## Aufräumen

Löscht Dateien im Output-Ordner, die nicht vom heutigen Tag sind.


```{r}

unlink(grep(datestamp,
            list.files("output",
                       full.names = TRUE),
            invert = TRUE,
            value = TRUE))


```



## Ordner erstellen

```{r}

#unlink("output", recursive = TRUE)
dir.create("output", showWarnings = FALSE)
dir.create("temp", showWarnings = FALSE)
dir.create("platzhalter", showWarnings = FALSE)

dir.create(dir.analysis, showWarnings = FALSE)

```



## Vollzitate statistischer Software schreiben

```{r}
knitr::write_bib(renv::dependencies()$Package,
                 "temp/packages.bib")
```




# Globale Variablen


## Packages definieren

```{targets global-packages, tar_globals = TRUE}

tar_option_set(packages = c("tarchetypes",
                            "RcppTOML",     # TOML-Dateien lesen und schreiben
							"testthat",     # Unit Tests
                            "fs",           # Verbessertes File Handling
                            "zip",          # Verbessertes ZIP Handling
                            "mgsub",        # Vektorisiertes Gsub
                            "httr",         # HTTP-Werkzeuge
                            "rvest",        # HTML/XML-Extraktion
                            "knitr",        # Professionelles Reporting
                            "kableExtra",   # Verbesserte Kable Tabellen
                            "pdftools",     # Verarbeitung von PDF-Dateien
                            "ggplot2",      # Datenvisualisierung
							"ggraph",       # Visualisierung von Graphen
                            "scales",       # Skalierung von Diagrammen
                            "data.table",   # Fortgeschrittene Datenverarbeitung
                            "readtext",     # TXT-Dateien einlesen
                            "quanteda",     # Computerlinguistik
                            "future",       # Parallelisierung
                            "future.apply"))# Funktionen für Future

tar_option_set(workspace_on_error = TRUE) # Save Workspace on Error

```


## Konfiguration


```{targets global-config, tar_globals = TRUE}

datestamp <- Sys.Date()

config <- RcppTOML::parseTOML("config.toml")

dir.analysis <- paste0(getwd(),
                       "/analysis")

## Caption for diagrams
caption <- paste("Fobbe | DOI:",
                 config$doi$data$version)


## Prefix for figure titles
prefix.figuretitle <- paste(config$project$shortname,
                            "| Version",
                            datestamp)

## File prefix
prefix.files <- paste0(config$project$shortname,
                       "_",
                       datestamp)


if (config$cores$max == TRUE){
    fullCores <- future::availableCores() - 1
}


if (config$cores$max == FALSE){
    fullCores <- as.integer(config$cores$number)
}

```




## Funktionen definieren

```{targets global-functions, tar_globals = TRUE}

lapply(list.files("functions", full.names = TRUE), source)

```



## Metadaten für TXT-Dateien definieren

```{targets global-txtvars, tar_globals = TRUE}

docvarnames <- c("gericht",
                 "spruchkoerper_db",
                 "leitsatz",
                 "datum",
                 "spruchkoerper_az",
                 "registerzeichen",
                 "eingangsnummer",
                 "eingangsjahr_az",
                 "zusatz_az",
                 "name",
                 "kollision")

```


## ZIP-Datei für Source definieren

```{targets global-sourcefiles, tar_globals = TRUE}

files.source.raw <-  c(list.files(pattern = "\\.R$|\\.toml$|\\.md$|\\.Rmd$"),
                       "R-fobbe-proto-package",
					   "reports",
                       "data",
                       "functions",
                       "tex",
                       "gpg",
                       "buttons",
                       list.files(pattern = "renv\\.lock|\\.Rprofile",
                                  all.files = TRUE),
                       list.files("renv",
                                  pattern = "activate\\.R",
                                  full.names = TRUE))

```






# Pipeline: Konstruktion




## File Tracking Targets

Mit diesem Abschnitt der Pipeline werden Input-Dateien getrackt und eingelesen. Mit der Option \enquote{format = "file"} werden für Input-Dateien Prüfsummen berechnet. Falls sich diese verändern werden alle von ihnen abhängigen Pipeline-Schritte als veraltet markiert und neu berechnet.



### Scope

Der Umfang der Auswertung der Datenbank des BGH.


```{targets tar.file0}
list(
    tar_target(file.scope,
               "data/CE-BGH_Scope.csv",
               format = "file"),
    tar_target(scope,
               fread(file.scope))
)
```


### Variablen

Die Variablen des Datensatzes, inklusive ihrer Erläuterung.


```{targets tar.file1}
list(
    tar_target(file.variables.codebook,
               "data/CE-BGH_Variables.csv",
               format = "file"),
    tar_target(variables.codebook,
               fread(file.variables.codebook))
)
```



### Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD)

Die Tabelle der Registerzeichen und der ihnen zugeordneten Verfahrensarten stammt aus dem folgenden Datensatz: \enquote{Seán Fobbe (2021). Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD). Version 1.0.1. Zenodo. DOI: 10.5281/zenodo.4569564.}

`

```{targets tar.file2}
list(
    tar_target(file.az.brd,
           "data/AZ-BRD_1-0-1_DE_Registerzeichen_Datensatz.csv",
           format = "file"),
     tar_target(az.brd,
                fread(file.az.brd))
     )
```

### Presidents and Vice-Presidents of the Federal Courts of Germany (PVP-FCG)

 Die Personendaten stammen aus folgendem Datensatz: \enquote{Seán Fobbe and Tilko Swalve (2021). Presidents and Vice-Presidents of the Federal Courts of Germany (PVP-FCG). Version 2021-04-08. Zenodo. DOI: 10.5281/zenodo.4568682}.


```{targets tar.file3}
list(
    tar_target(file.presidents,
           "data/PVP-FCG_2021-04-08_GermanFederalCourts_Presidents.csv",
           format = "file"),
     tar_target(presidents,
                fread(file.presidents))
     )
```



```{targets tar.file4}
list(
    tar_target(file.vpresidents,
           "data/PVP-FCG_2021-04-08_GermanFederalCourts_VicePresidents.csv",
           format = "file"),
     tar_target(vpresidents,
                fread(file.vpresidents))
     )
```




### Source Code

Dies sind alle Dateien, die den Source Code für den Datensatz bereitstellen.

```{targets tar.file5}
tar_target(files.source,
           files.source.raw,
           format = "file")

```



### Changelog

```{targets tar.file6}
tar_target(changelog,
           "CHANGELOG.md",
           format = "file")
```



## Download Targets


### Vorläufige Download-Tabelle erstellen

Abfrage der Datenbank des BGH und erstellen der vorläufigen Download-Tabelle.

```{targets tar.download1}
tar_target(dt.download,
           f.download_table_make(x = scope,
                                 debug.toggle = config$debug$toggle,
                                 debug.pages = config$debug$pages))

```
	

### Download-Tabelle Bereinigen

Die Aktenzeichen und Spruchkörper werden bereinigt und gespeichert.

```{targets tar.download2}

list(
    tar_target(az_clean,
                f.clean_az_bgh(dt.download$az)),
    tar_target(spruch_clean,
               f.clean_spruch_bgh(dt.download$spruch))
    )
				
				
```

### Finale Download-Tabelle erstellen

Die bereinigten Variablen werden hier mit der vorläufigen Download-Tabelle zusammengeführt, weitere Bereinigungen durchgeführt, weitere Variablen aus den Bemerkungen extrahiert und schließlich auf ihre Konformität mit der Beschreibung im Codebook getestet.



```{targets tar.download3}

tar_target(dt.download.final,
           f.download_table_finalize(x = dt.download,
                                     az = az_clean,
                                     spruch = spruch_clean))
```



### Download durchführen


```{targets tar.download4}
tar_target(files.pdf,
                f.download(url = dt.download.final$url,
                           filename = dt.download.final$doc_id,
                           dir = "pdf",
                           sleep.min = 0,
                           sleep.max = 0.1,
                           retries = 3,
                           retry.sleep.min = 2,
                           retry.sleep.max = 5,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```




## Convert Targets

Durch diesen Abschnitt der Pipeline werden die PDF-Dateien in TXT konvertiert und mitsamt den Variablen in ihren Dateinamen eingelesen. Beim Einlesen werden die in PDF-Dateien üblichen über Zeilen gebrochene Wörter wieder zusammengefügt.




```{targets tar.convert}

list(tar_target(files.txt,
                f.tar_pdf_extract(files.pdf),
                format = "file"),
     tar_target(dt.bgh,
                f.readtext(x = files.txt,
                           docvarnames = docvarnames))
     )
					
```					


## Enhance Targets

Dieser Abschnitt der Pipeline berechnet diverse Verbesserungen für den Datensatz und führt diese am Ende zusammen.


### Daten standardisieren

Das Datum wird im ISO-Format standardisiert und die Variablen \enquote{entscheidungsjahr} und \enquote{eingangsjahr\_iso} hinzugefügt.


```{targets tar.enhance1}
tar_target(dt.bgh.datecleaned,
                f.clean_dates(dt.bgh))
```


### Variable erstellen: \enquote{verfahrensart}

Die Variable \enquote{verfahrensart} wird aus den Registerzeichen berechnet.

```{targets tar.enhance2}
tar_target(var_verfahrensart,
                f.var_verfahrensart(dt.bgh.datecleaned$registerzeichen,
                                    az.brd = az.brd,
                                    gericht = "BGH"))
```





### Variable erstellen: \enquote{aktenzeichen}

Das Aktenzeichen wird aus seinen Komponenten berechnet.


```{targets tar.enhance3}
tar_target(var_aktenzeichen,
                f.var_aktenzeichen(dt.bgh.datecleaned,
                                   az.brd = az.brd,
                                   gericht = "BGH"))
```



### Variable erstellen: \enquote{ecli}

Die ECLI wird aus ihren Komponenten berechnet.



```{targets tar.enhance4}
tar_target(var_ecli,
           f.var_ecli_bgh(x = dt.bgh.datecleaned,
                          az.brd = az.brd))
```




### Variable erstellen: \enquote{praesi}


```{targets tar.enhance5}
tar_target(var_praesi,
           f.presidents(datum = dt.bgh.datecleaned$datum,
                        gericht = "BGH",
						pvp.fcg = presidents))
```

### Variable erstellen: \enquote{vpraesi}


```{targets tar.enhance6}
tar_target(var_vpraesi,
           f.presidents(datum = dt.bgh.datecleaned$datum,
                        gericht = "BGH",
						pvp.fcg = vpresidents))
```






### Variable erstellen: \enquote{entscheidung\_typ}

Der Typ der Entscheidung wird aus dem Text extrahiert.


```{targets tar.enhance7}
tar_target(var_entscheidung_typ,
                f.var_entscheidung_typ(dt.bgh.datecleaned$text))
```



### Variablen erstellen: \enquote{zeichen, token, typen, saetze}

Berechnung klassischer linguistischer Kennzahlen.



```{targets tar.enhance8}
tar_target(var_lingstats,
                f.lingstats(dt.bgh.datecleaned,
                            multicore = config$parallel$lingsummarize,
                            cores = fullCores,
                            germanvars = TRUE))
```





### Konstanten erstellen

Konstanten die dem Datensatz wichtige Herkunftsinformationen hinzufügen. Darunter sind die Versionsnummer, die Version DOI, die Concept DOI und die Lizenz.



```{targets tar.enhance9}
tar_target(var_constants,
           data.frame(version = as.character(datestamp),
                      doi_concept = config$doi$data$concept,
                      doi_version = config$doi$data$version,
                      lizenz = as.character(config$license$data))[rep(1,
                                                                      nrow(dt.bgh.datecleaned)),])
```





### Zusätzliche Variablen zusammenführen

```{targets tar.enhance10}
tar_target(vars_additional,
           data.table(verfahrensart = var_verfahrensart,
                      aktenzeichen = var_aktenzeichen,
                      ecli = var_ecli,
                      praesi = var_praesi,
                      v_praesi = var_vpraesi,
					  entscheidung_typ = var_entscheidung_typ,
                      var_lingstats,
                      var_constants))

```



### Finalen Datensatz erstellen

Die Verbesserungen der vorherigen Schritte werden in dieser Funktion zusammengefügt um den finalen Datenatz herzustellen.


```{targets tar.enhance11}
tar_target(dt.bgh.final,
           f.finalize(x = dt.bgh.datecleaned,
                      download.table = dt.download.final,
                      vars.additional = vars_additional,
                      varnames = variables.codebook$varname))

```


### Variante erstellen: Nur Metadaten

Hier wird die Text-Variable entfernt, um eine deutlich platzsparendere Variante des Datensatzes zu erstellen. Enthalten sind nur noch die Metadaten.



```{targets tar.enhance14}
tar_target(dt.bgh.meta,
                dt.bgh.final[, !"text"])

```




## Write Targets

Dieser Abschnitt der Pipeline schreibt den Datensatz und alle Hash-Prüfsummen auf die Festplatte.



### CSV schreiben: Voller Datensatz

```{targets tar.write1}
tar_target(csv.full,
           f.tar_fwrite(x = dt.bgh.final,
                        filename = file.path("output",
                                             paste0(prefix.files,
                                                    "_DE_CSV_Datensatz.csv"))
                        )
           )
```



### CSV schreiben: Metadaten


```{targets tar.write2}
tar_target(csv.meta,
           f.tar_fwrite(x = dt.bgh.meta,
                        filename = file.path("output",
                                             paste0(prefix.files,
                                                    "_DE_CSV_Metadaten.csv"))
                        )
           )
```





## Report Targets

Dieser Abschnitt der Pipeline erstellt die finalen Berichte (Codebook und Robustness Checks).



### LaTeX-Definitionen schreiben

Um Variablen aus der Pipeline in die LaTeX-Kompilierung einzuführen, müssen diese als .tex-Datei auf die Festplatte geschrieben werden.

```{targets tar.report1}
tar_target(latexdefs,
                f.latexdefs(config,
                            dir = "temp",
                            version = datestamp),
	       format = "file")

```

### Zusammenfassungen linguistischer Kennwerte berechnen

```{targets tar.report2}
tar_target(lingstats.summary,
                f.lingstats_summary(dt.bgh.full,
                                    germanvars = TRUE))

```


### Report erstellen: Robustness Checks

```{targets tar.report3}
tarchetypes::tar_render(report.robustness,
                        file.path("reports",
                                  "RobustnessChecks.Rmd"),
                        output_file = file.path("../output",
                                                paste0(config$project$shortname,
                                                       "_",
                                                       datestamp,
                                                       "_RobustnessChecks.pdf")))

```





## ZIP Targets

Diese Abschnitt der Pipeline erstellt ZIP-Archive für alle zentralen Rechenergebnisse und speichert diese im Ordner \enquote{output}.


### ZIP erstellen: PDF-Dateien (alle Entscheidungen)

Hinweis: die verpackten PDF-Dateien werden auf die im finalen Datensatz enthaltenen Dokumente beschränkt (Bereinigung um Platzhalter-Dokumente).


```{targets tar.zip1}

tar_target(zip.pdf.all,
           f.tar_zip(x = intersect(files.pdf,
                                   file.path("pdf",
                                             gsub("\\.txt",
                                                  "\\.pdf",
                                                  dt.bgh.final$doc_id))),
                     filename = paste(prefix.files,
                                      "DE_PDF_Datensatz.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick"),
           format = "file")


```



### ZIP erstellen: PDF-Dateien (nur Leitsatzentscheidungen)

```{targets tar.zip2}

tar_target(zip.pdf.leitsatz,
           f.tar_zip(x = intersect(files.pdf,
                                   file.path("pdf",
                                             gsub("\\.txt",
                                                  "\\.pdf",
                                                  dt.bgh.final[leitsatz == "LE"]$doc_id))),
                     filename = paste(prefix.files,
                                      "DE_PDF_Leitsatz-Entscheidungen.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick"),
           format = "file")
```




### ZIP erstellen: PDF-Dateien (nur benannte Entscheidungen)

```{targets tar.zip3}
tar_target(zip.pdf.benannt,
                f.tar_zip(x = intersect(files.pdf,
                                   file.path("pdf",
                                             gsub("\\.txt",
                                                  "\\.pdf",
                                                  dt.bgh.final[is.na(name) == FALSE]$doc_id))),
                              filename = paste(prefix.files,
                                               "DE_PDF_Entscheidungen-mit-Namen.zip",
                                               sep = "_"),
                              dir = "output",
                              mode = "cherry-pick"),
                format = "file")
```





### ZIP erstellen: TXT-Dateien

```{targets tar.zip4}
tar_target(zip.txt,
           f.tar_zip(x = intersect(files.txt, file.path("txt", dt.bgh.final$doc_id)),
                     filename = paste(prefix.files,
                                      "DE_TXT_Datensatz.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick"),
           format = "file")
```


### ZIP erstellen: CSV-Datei (voller Datensatz)


```{targets tar.zip5}
tar_target(zip.csv.full,
                f.tar_zip(csv.full,
                              filename = gsub("\\.csv", "\\.zip", basename(csv.full)),
                              dir = "output",
                              mode = "cherry-pick"),
                format = "file")
```



### ZIP erstellen: CSV-Datei (nur Metadaten)


```{targets tar.zip6}
tar_target(zip.csv.meta,
                f.tar_zip(csv.meta,
                              filename = gsub("\\.csv", "\\.zip", basename(csv.meta)),
                              dir = "output",
                              mode = "cherry-pick"),
                format = "file")
```




### ZIP erstellen: Analyse-Dateien

```{targets tar.zip7}
tar_target(zip.analysis,
           f.tar_zip("analysis/",
                     filename = paste(prefix.files,
                                      "DE_Analyse.zip",
                                      sep = "_"),
                     dir = "output",
                     mode = "cherry-pick",
                     report.codebook,    # manually enforced dependency relationship
                     report.robustness), # manually enforced dependency relationship
           format = "file")
```





### ZIP erstellen: Source Code


```{targets tar.zip8}
tar_target(zip.source,
                f.tar_zip(files.source,
                              filename = paste0(prefix.files,
                                                "_Source_Code.zip"),
                              dir = "output",
                              mode = "mirror"),
                format = "file")
```











# Pipeline: Kompilierung



## Durchführen der Kompilierung

```{r pipeline-run, results = "hide"}
tar_make()
```



## Visualisierung

```{r, pipeline-graph, fig.width = 7, fig.height = 9}

edgelist <- tar_network(targets_only = TRUE)$edges
setDT(edgelist)

g  <- igraph::graph.data.frame(edgelist,
                               directed = TRUE)


ggraph(g,
       'sugiyama') + 
    geom_edge_diagonal(colour = "grey")+
    geom_node_point()+
    geom_node_text(aes(label = name),
                   size = 2,
                   repel = TRUE)+
    theme_void()

```
                       



# Pipeline: Analyse


## Gesamte Liste

Die vollständige Liste aller Targets, inklusive ihres Types und ihrer Größe. Targets die auf Dateien verweisen (z.B. alle PDF-Dateien) geben die Gesamtgröße der Dateien auf der Festplatte an.





```{r, pipeline-list}

meta <- tar_meta(fields = c("type", "bytes"), complete_only = TRUE)
setDT(meta)
meta$MB <- round(meta$bytes / 1e6, digits = 2)

# Gesamter Speicherplatzverbrauch
sum(meta$MB)

kable(meta[order(type, name)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```

\newpage
## Timing

### Gesamte Laufzeit

```{r, pipeline-runtime}
meta <- tar_meta(fields = c("time", "seconds"), complete_only = TRUE)
setDT(meta)
meta$mins <- round(meta$seconds / 60, digits = 2)

runtime.sum <- sum(meta$seconds)

## Sekunden
print(runtime.sum)

## Minuten
runtime.sum / 60

## Stunden
runtime.sum / 3600
```

### Laufzeit einzelner Targets

Der Zeitpunkt an dem die Targets berechnet wurden und ihre jeweilige Laufzeit in Sekunden.


```{r, pipeline-timing}
kable(meta[order(-seconds)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```



\newpage
## Warnungen


```{r, pipeling-warnings}

meta <- tar_meta(fields = "warnings", complete_only = TRUE)
setDT(meta)

kable(meta,
      format = "latex",
      align = c("P{4cm}", "p{10cm}"),
      booktabs = TRUE,
      longtable = TRUE)


```



## Fehlermeldungen

```{r, pipeline-errors}

meta <- tar_meta(fields = "error", complete_only = TRUE)
setDT(meta)

kable(meta,
      format = "latex",
      align = c("P{4cm}", "p{10cm}"),
      booktabs = TRUE,
      longtable = TRUE)


```







\newpage

```{r, results = "asis", echo = FALSE}
cat(readLines("CHANGELOG.md"),
    sep = "\n")

```


# Abschluss

```{r}

## Datumsstempel
print(datestamp) 

## Datum und Uhrzeit (Anfang)
print(begin.script)


## Datum und Uhrzeit (Ende)
end.script <- Sys.time()
print(end.script)


## Laufzeit des gesamten Skriptes
print(end.script - begin.script)

```


# Parameter für strenge Replikationen


```{r}
system2("openssl", "version", stdout = TRUE)

sessionInfo()

```


# Literaturverzeichnis
